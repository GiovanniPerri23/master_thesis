{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import math\n",
    "from torch import nn, Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# This relates to plotting datetime values with matplotlib:\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "from typing import Optional, Any, Union, Callable, Tuple\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Time Series Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: \n",
    "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    https://github.com/LiamMaclean216/Pytorch-Transfomer/blob/master/utils.py \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dropout: float = 0.1, max_seq_len: int = 24*31, d_model: int = 24):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dropout: the dropout rate\n",
    "            max_seq_len: the maximum length of the input sequences\n",
    "            d_model: The dimension of the output of sub-layers in the model \n",
    "                     (Vaswani et al, 2017)\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Create constant positional encoding matrix with values \n",
    "        # dependent on position and i\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        \n",
    "        exp_input = torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        \n",
    "        div_term = torch.exp(exp_input) # Returns a new tensor with the exponential of the elements of exp_input\n",
    "        \n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # torch.Size([target_seq_len, dim_val])\n",
    "\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1) # torch.Size([target_seq_len, input_size, dim_val])\n",
    "\n",
    "        # register that pe is not a model parameter\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, enc_seq_len, dim_val]\n",
    "        \"\"\"\n",
    "\n",
    "        add = self.pe[:x.size(1), :].squeeze(1)\n",
    "\n",
    "        x = x + add\n",
    "\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, \n",
    "        input_size: int,\n",
    "        dec_seq_len: int,\n",
    "        max_seq_len: int,\n",
    "        out_seq_len: int=58,\n",
    "        dim_val: int=512,  \n",
    "        n_encoder_layers: int=4,\n",
    "        n_decoder_layers: int=4,\n",
    "        n_heads: int=8,\n",
    "        dropout_encoder: float=0.2, \n",
    "        dropout_decoder: float=0.2,\n",
    "        dropout_pos_enc: float=0.2,\n",
    "        dim_feedforward_encoder: int=2048,\n",
    "        dim_feedforward_decoder: int=2048,\n",
    "        ): \n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size: int, number of input variables. 1 if univariate.\n",
    "            dec_seq_len: int, the length of the input sequence fed to the decoder\n",
    "            max_seq_len: int, length of the longest sequence the model will \n",
    "                         receive. Used in positional encoding. \n",
    "            out_seq_len: int, the length of the model's output (i.e. the target\n",
    "                         sequence length)\n",
    "            dim_val: int, aka d_model. All sub-layers in the model produce \n",
    "                     outputs of dimension dim_val\n",
    "            n_encoder_layers: int, number of stacked encoder layers in the encoder\n",
    "            n_decoder_layers: int, number of stacked encoder layers in the decoder\n",
    "            n_heads: int, the number of attention heads (aka parallel attention layers)\n",
    "            dropout_encoder: float, the dropout rate of the encoder\n",
    "            dropout_decoder: float, the dropout rate of the decoder\n",
    "            dropout_pos_enc: float, the dropout rate of the positional encoder\n",
    "            dim_feedforward_encoder: int, number of neurons in the linear layer \n",
    "                                     of the encoder\n",
    "            dim_feedforward_decoder: int, number of neurons in the linear layer \n",
    "                                     of the decoder\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__() \n",
    "\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "#         self.pe = PositionalEncoder()\n",
    "\n",
    "        print(\"input_size is: {}\".format(input_size))\n",
    "        print(\"dim_val is: {}\".format(dim_val))\n",
    "\n",
    "        # Creating the three linear layers needed for the model\n",
    "        self.encoder_input_layer = nn.Linear(\n",
    "            in_features=input_size, \n",
    "            out_features=dim_val \n",
    "            )\n",
    "\n",
    "        self.decoder_input_layer = nn.Linear(\n",
    "            in_features=input_size, \n",
    "            out_features=dim_val \n",
    "            )  \n",
    "\n",
    "        self.linear_mapping = nn.Linear(\n",
    "            in_features=out_seq_len*dim_val,\n",
    "            out_features=out_seq_len\n",
    "            )\n",
    "\n",
    "        # Create positional encoder   ###changed\n",
    "        self.positional_encoding_layer = PositionalEncoder(\n",
    "            d_model=dim_val,\n",
    "            dropout=dropout_pos_enc,\n",
    "            max_seq_len=max_seq_len\n",
    "            )\n",
    "\n",
    "        # The encoder layer used in the paper is identical to the one used by\n",
    "        # Vaswani et al (2017) on which the PyTorch module is based.\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_val, \n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward_encoder,\n",
    "            dropout=dropout_encoder,\n",
    "            batch_first=True\n",
    "            )\n",
    "\n",
    "        # Stack the encoder layers in nn.TransformerDecoder\n",
    "        # It seems the option of passing a normalization instance is redundant\n",
    "        # in my case, because nn.TransformerEncoderLayer per default normalizes\n",
    "        # after each sub-layer\n",
    "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=n_encoder_layers, \n",
    "            norm=None\n",
    "            )\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=dim_val,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward_decoder,\n",
    "            dropout=dropout_decoder,\n",
    "            batch_first=True\n",
    "            )\n",
    "\n",
    "        # Stack the decoder layers in nn.TransformerDecoder\n",
    "        # It seems the option of passing a normalization instance is redundant\n",
    "        # in my case, because nn.TransformerDecoderLayer per default normalizes\n",
    "        # after each sub-layer\n",
    "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=decoder_layer,\n",
    "            num_layers=n_decoder_layers, \n",
    "            norm=None\n",
    "            )\n",
    "\n",
    "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Tensor=None, \n",
    "                tgt_mask: Tensor=None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: the encoder's output sequence. Shape: (S,E) for unbatched input, \n",
    "                 (S, N, E) if batch_first=False or (N, S, E) if \n",
    "                 batch_first=True, where S is the source sequence length, \n",
    "                 N is the batch size, and E is the feature number\n",
    "            tgt: the sequence to the decoder. Shape: (T,E) for unbatched input, \n",
    "                 (T, N, E)(T,N,E) if batch_first=False or (N, T, E) if \n",
    "                 batch_first=True, where T is the target sequence length, \n",
    "                 N is the batch size, E is the feature number.\n",
    "            src_mask: the mask for the src sequence to prevent the model from \n",
    "                      using data points from the target sequence\n",
    "            tgt_mask: the mask for the tgt sequence to prevent the model from\n",
    "                      using data points from the target sequence\n",
    "        \"\"\"\n",
    "\n",
    "        # Pass throguh the input layer right before the encoder\n",
    "        src = self.encoder_input_layer(src)\n",
    "\n",
    "        # Pass through the positional encoding layer\n",
    "        src = self.positional_encoding_layer(src)\n",
    "\n",
    "        # Pass through all the stacked encoder layers in the encoder\n",
    "        # Masking is only needed in the encoder if input sequences are padded\n",
    "        # which they are not in this time series use case, because all my\n",
    "        # input sequences are naturally of the same length. \n",
    "        # (https://github.com/huggingface/transformers/issues/4083)\n",
    "        src = self.encoder(\n",
    "            src=src\n",
    "            )\n",
    "\n",
    "        # Pass decoder input through decoder input layer\n",
    "        decoder_output = self.decoder_input_layer(tgt)\n",
    "\n",
    "        # Pass throguh decoder\n",
    "        decoder_output = self.decoder(\n",
    "            tgt=decoder_output,\n",
    "            memory=src,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=src_mask\n",
    "            )\n",
    "\n",
    "        # Pass through the linear mapping layer\n",
    "        decoder_output= self.linear_mapping(decoder_output.flatten(start_dim=1))\n",
    "\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size is: 1\n",
      "dim_val is: 24\n"
     ]
    }
   ],
   "source": [
    "## Model parameters\n",
    "dim_val = 24 # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
    "n_heads = 8 # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
    "n_decoder_layers = 4 # Number of times the decoder layer is stacked in the decoder\n",
    "n_encoder_layers = 4 # Number of times the encoder layer is stacked in the encoder\n",
    "input_size = 1 # The number of input variables. 1 if univariate forecasting.\n",
    "dec_seq_len = 24 # length of input given to decoder. Can have any integer value.\n",
    "enc_seq_len = 24 # length of input given to encoder. Can have any integer value.\n",
    "output_sequence_length = 24 # Length of the target sequence, i.e. how many time steps should your forecast cover\n",
    "max_seq_len = enc_seq_len # What's the longest sequence the model will encounter? Used to make the positional encoder\n",
    "\n",
    "model = TimeSeriesTransformer(\n",
    "    dim_val=dim_val,\n",
    "    input_size=input_size, \n",
    "    dec_seq_len=dec_seq_len,\n",
    "    max_seq_len=max_seq_len,\n",
    "    out_seq_len=output_sequence_length, \n",
    "    n_decoder_layers=n_decoder_layers,\n",
    "    n_encoder_layers=n_encoder_layers,\n",
    "    n_heads=n_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation for transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class used for transformer models.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        data: torch.tensor,\n",
    "        indices: list, \n",
    "        enc_seq_len: int, \n",
    "        dec_seq_len: int, \n",
    "        target_seq_len: int\n",
    "        ) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: tensor, the entire train, validation or test data sequence \n",
    "                        before any slicing. If univariate, data.size() will be \n",
    "                        [number of samples, number of variables]\n",
    "                        where the number of variables will be equal to 1 + the number of\n",
    "                        exogenous variables. Number of exogenous variables would be 0\n",
    "                        if univariate.\n",
    "            indices: a list of tuples. Each tuple has two elements:\n",
    "                     1) the start index of a sub-sequence\n",
    "                     2) the end index of a sub-sequence. \n",
    "                     The sub-sequence is split into src, trg and trg_y later.  \n",
    "            enc_seq_len: int, the desired length of the input sequence given to the\n",
    "                     the first layer of the transformer model.\n",
    "            target_seq_len: int, the desired length of the target sequence (the output of the model)\n",
    "            target_idx: The index position of the target variable in data. Data\n",
    "                        is a 2D tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.indices = indices\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        print(\"From get_src_trg: data size = {}\".format(data.size()))\n",
    "\n",
    "        self.enc_seq_len = enc_seq_len\n",
    "\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "\n",
    "        self.target_seq_len = target_seq_len\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a tuple with 3 elements:\n",
    "        1) src (the encoder input)\n",
    "        2) trg (the decoder input)\n",
    "        3) trg_y (the target)\n",
    "        \"\"\"\n",
    "        # Get the first element of the i'th tuple in the list self.indicesasdfas\n",
    "        start_idx = self.indices[index][0]\n",
    "\n",
    "        # Get the second (and last) element of the i'th tuple in the list self.indices\n",
    "        end_idx = self.indices[index][1]\n",
    "\n",
    "        sequence = self.data[start_idx:end_idx]\n",
    "\n",
    "        #print(\"From __getitem__: sequence length = {}\".format(len(sequence)))\n",
    "\n",
    "        src, trg, trg_y = self.get_src_trg(\n",
    "            sequence=sequence,\n",
    "            enc_seq_len=self.enc_seq_len,\n",
    "            dec_seq_len=self.dec_seq_len,\n",
    "            target_seq_len=self.target_seq_len\n",
    "            )\n",
    "\n",
    "        return src, trg, trg_y\n",
    "    \n",
    "    def get_src_trg(\n",
    "        self,\n",
    "        sequence: torch.Tensor, \n",
    "        enc_seq_len: int, \n",
    "        dec_seq_len: int, \n",
    "        target_seq_len: int\n",
    "        ) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n",
    "\n",
    "        \"\"\"\n",
    "        Generate the src (encoder input), trg (decoder input) and trg_y (the target)\n",
    "        sequences from a sequence. \n",
    "        Args:\n",
    "            sequence: tensor, a 1D tensor of length n where \n",
    "                    n = encoder input length + target sequence length  \n",
    "            enc_seq_len: int, the desired length of the input to the transformer encoder\n",
    "            target_seq_len: int, the desired length of the target sequence (the \n",
    "                            one against which the model output is compared)\n",
    "        Return: \n",
    "            src: tensor, 1D, used as input to the transformer model\n",
    "            trg: tensor, 1D, used as input to the transformer model\n",
    "            trg_y: tensor, 1D, the target sequence against which the model output\n",
    "                is compared when computing loss. \n",
    "        \n",
    "        \"\"\"\n",
    "        assert len(sequence) == enc_seq_len + target_seq_len, \"Sequence length does not equal (input length + target length)\"\n",
    "        \n",
    "        # encoder input\n",
    "        src = sequence[:enc_seq_len] \n",
    "        \n",
    "        # decoder input. As per the paper, it must have the same dimension as the \n",
    "        # target sequence, and it must contain the last value of src, and all\n",
    "        # values of trg_y except the last (i.e. it must be shifted right by 1)\n",
    "        trg = sequence[enc_seq_len-1:len(sequence)-1]\n",
    "        \n",
    "        assert len(trg) == target_seq_len, \"Length of trg does not match target sequence length\"\n",
    "\n",
    "        # The target sequence against which the model output will be compared to compute loss\n",
    "        trg_y = sequence[-target_seq_len:]\n",
    "\n",
    "        assert len(trg_y) == target_seq_len, \"Length of trg_y does not match target sequence length\"\n",
    "\n",
    "        return src, trg, trg_y.squeeze(-1) # change size from [batch_size, target_seq_len, num_features] to [batch_size, target_seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(dim1: int, dim2: int, dim3: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generates an upper-triangular matrix of -inf, with zeros on diag.\n",
    "    Modified from: \n",
    "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    Args:\n",
    "        dim1: int, batch_size * n_heads\n",
    "        dim2: int. For src and trg masking this must be target sequence length. \n",
    "        dim3: int. For src masking, this must be encoder sequence length.\n",
    "              For trg masking, this must be target sequence length \n",
    "    Return:\n",
    "        A Tensor of shape [dim1, dim2, dim3]\n",
    "    \"\"\"\n",
    "    return torch.triu(torch.ones(dim1, dim2, dim3) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_input_target(num_obs, input_len, step_size, forecast_horizon, target_len):\n",
    "        \"\"\"\n",
    "        Produce all the start and end index positions of all sub-sequences.\n",
    "        The indices will be used to split the data into sub-sequences on which \n",
    "        the models will be trained. \n",
    "        Returns a tuple with four elements:\n",
    "        1) The index position of the first element to be included in the input sequence\n",
    "        2) The index position of the last element to be included in the input sequence\n",
    "        3) The index position of the first element to be included in the target sequence\n",
    "        4) The index position of the last element to be included in the target sequence\n",
    "        \n",
    "        Args:\n",
    "            num_obs (int): Number of observations in the entire dataset for which\n",
    "                            indices must be generated.\n",
    "            input_len (int): Length of the input sequence (a sub-sequence of \n",
    "                             of the entire data sequence)\n",
    "            step_size (int): Size of each step as the data sequence is traversed.\n",
    "                             If 1, the first sub-sequence will be indices 0-input_len, \n",
    "                             and the next will be 1-input_len.\n",
    "            forecast_horizon (int): How many index positions is the target away from\n",
    "                                    the last index position of the input sequence?\n",
    "                                    If forecast_horizon=1, and the input sequence\n",
    "                                    is data[0:10], the target will be data[11:taget_len].\n",
    "            target_len (int): Length of the target / output sequence.\n",
    "        \"\"\"\n",
    "\n",
    "        input_len = round(input_len) # just a precaution\n",
    "        start_position = 0\n",
    "        stop_position = num_obs-1 # because of 0 indexing\n",
    "        \n",
    "        subseq_first_idx = start_position\n",
    "        subseq_last_idx = start_position + input_len\n",
    "        target_first_idx = subseq_last_idx + forecast_horizon\n",
    "        target_last_idx = target_first_idx + target_len \n",
    "        print(\"target_last_idx is {}\".format(target_last_idx))\n",
    "        print(\"stop_position is {}\".format(stop_position))\n",
    "        indices = []\n",
    "        while target_last_idx <= stop_position:\n",
    "            indices.append((subseq_first_idx, subseq_last_idx, target_first_idx, target_last_idx))\n",
    "            subseq_first_idx += step_size\n",
    "            subseq_last_idx += step_size\n",
    "            target_first_idx = subseq_last_idx + forecast_horizon\n",
    "            target_last_idx = target_first_idx + target_len\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_entire_sequence(data: pd.DataFrame, window_size: int, step_size: int) -> list:\n",
    "        \"\"\"\n",
    "        Produce all the start and end index positions that is needed to produce\n",
    "        the sub-sequences. \n",
    "        Returns a list of tuples. Each tuple is (start_idx, end_idx) of a sub-\n",
    "        sequence. These tuples should be used to slice the dataset into sub-\n",
    "        sequences. These sub-sequences should then be passed into a function\n",
    "        that slices them into input and target sequences. \n",
    "        \n",
    "        Args:\n",
    "            num_obs (int): Number of observations (time steps) in the entire \n",
    "                           dataset for which indices must be generated, e.g. \n",
    "                           len(data)\n",
    "            window_size (int): The desired length of each sub-sequence. Should be\n",
    "                               (input_sequence_length + target_sequence_length)\n",
    "                               E.g. if you want the model to consider the past 100\n",
    "                               time steps in order to predict the future 50 \n",
    "                               time steps, window_size = 100+50 = 150\n",
    "            step_size (int): Size of each step as the data sequence is traversed \n",
    "                             by the moving window.\n",
    "                             If 1, the first sub-sequence will be [0:window_size], \n",
    "                             and the next will be [1:window_size].\n",
    "        Return:\n",
    "            indices: a list of tuples\n",
    "        \"\"\"\n",
    "\n",
    "        stop_position = len(data)-1 # 1- because of 0 indexing\n",
    "        \n",
    "        # Start the first sub-sequence at index position 0\n",
    "        subseq_first_idx = 0\n",
    "        \n",
    "        subseq_last_idx = window_size\n",
    "        \n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "\n",
    "            indices.append((subseq_first_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            \n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir: Union[str, Path] = \"../input/vtpeyton-manning\",  \n",
    "    timestamp_col_name: str=\"ds\",norm: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read data from csv file and return pd.Dataframe object\n",
    "    Args:\n",
    "        data_dir: str or Path object specifying the path to the directory \n",
    "                  containing the data\n",
    "        target_col_name: str, the name of the column containing the target variable\n",
    "        timestamp_col_name: str, the name of the column or named index \n",
    "                            containing the timestamps\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that `data_dir` is a Path object\n",
    "#     print(data_dir)\n",
    "    data_dir = Path(data_dir)\n",
    "#     print(data_dir)\n",
    "\n",
    "    # Read csv file\n",
    "    csv_files = list(data_dir.glob(\"*.csv\"))\n",
    "#     print(csv_files)\n",
    "    if len(csv_files) > 1:\n",
    "        raise ValueError(\"data_dir contains more than 1 csv file. Must only contain 1\")\n",
    "\n",
    "    data_path = csv_files[0]\n",
    "\n",
    "    print(\"Reading file in {}\".format(data_path))\n",
    "    \n",
    "    data = pd.read_csv(\n",
    "        data_path, \n",
    "        parse_dates=[timestamp_col_name], \n",
    "        index_col=[timestamp_col_name], \n",
    "        infer_datetime_format=True,\n",
    "        low_memory=False\n",
    "    )\n",
    "\n",
    "    # Make sure all \"n/e\" values have been removed from df. \n",
    "    if is_ne_in_df(data):\n",
    "        raise ValueError(\"data frame contains 'n/e' values. These must be handled\")\n",
    "#     print(data.head())\n",
    "    data = to_numeric_and_downcast_data(data)\n",
    "    \n",
    "    if norm == True:\n",
    "        initialize_norm = standardize_data()\n",
    "        data = initialize_norm.to_normalize(data)\n",
    "#     print(data.head())\n",
    "    # Make sure data is in ascending order by timestamp\n",
    "    data.sort_values(by=[timestamp_col_name], inplace=True)\n",
    "\n",
    "    return initialize_norm, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
